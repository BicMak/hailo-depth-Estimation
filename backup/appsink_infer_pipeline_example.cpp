#include <gst/gst.h>
#include <gst/app/gstappsink.h>  // ì¶”ê°€
#include <gst/app/gstappsrc.h>   // ì¶”ê°€
#include <glib.h>
#include <iostream>
#include <string>
#include <opencv2/opencv.hpp>



// decodebinì˜ pad-added ì½œë°± (ì¹´ë©”ë¼ê°€ MJPEGì¼ ê²½ìš°)
static void on_pad_added(GstElement *element, GstPad *pad, gpointer data) {
    GstElement *convert = (GstElement*)data;
    
    GstCaps *caps = gst_pad_get_current_caps(pad);
    if (caps) {
        GstStructure *structure = gst_caps_get_structure(caps, 0);
        const gchar *name = gst_structure_get_name(structure);
        
        if (g_str_has_prefix(name, "video")) {
            GstPad *sink_pad = gst_element_get_static_pad(convert, "sink");
            
            if (!gst_pad_is_linked(sink_pad)) {
                GstPadLinkReturn ret = gst_pad_link(pad, sink_pad);
                if (ret != GST_PAD_LINK_OK) {
                    std::cerr << "íŒ¨ë“œ ì—°ê²° ì‹¤íŒ¨" << std::endl;
                }
            }
            
            gst_object_unref(sink_pad);
        }
        
        gst_caps_unref(caps);
    }
}

// ë²„ìŠ¤ ë©”ì‹œì§€ ì½œë°±
static gboolean on_message(GstBus *bus, GstMessage *message, gpointer data) {
    GMainLoop *loop = (GMainLoop*)data;
    
    switch (GST_MESSAGE_TYPE(message)) {
        case GST_MESSAGE_ERROR: {
            GError *err;
            gchar *debug;
            gst_message_parse_error(message, &err, &debug);
            std::cerr << "ì—ëŸ¬: " << err->message << std::endl;
            std::cerr << "ë””ë²„ê·¸: " << debug << std::endl;
            g_error_free(err);
            g_free(debug);
            g_main_loop_quit(loop);
            break;
        }
        case GST_MESSAGE_EOS:
            std::cout << "ì¬ìƒ ì™„ë£Œ" << std::endl;
            g_main_loop_quit(loop);
            break;
        case GST_MESSAGE_WARNING: {
            GError *warn;
            gchar *debug;
            gst_message_parse_warning(message, &warn, &debug);
            std::cerr << "ê²½ê³ : " << warn->message << std::endl;
            g_error_free(warn);
            g_free(debug);
            break;
        }
        default:
            break;
    }
    
    return TRUE;
}

struct FrameData {
    cv::Mat frame;
};

// ë©”ì¸ ë£¨í”„ì—ì„œ ì‹¤í–‰ë  í•¨ìˆ˜
static gboolean show_frame_idle(gpointer user_data) {
    FrameData *data = (FrameData *)user_data;
    
    // imshow ëŒ€ì‹  íŒŒì¼ ì €ì¥
    static int frame_count = 0;
    cv::imwrite("frame_" + std::to_string(frame_count++) + ".png", data->frame);
    std::cout << "Frame saved: " << frame_count << std::endl;
    
    delete data;
    return FALSE;
    }

static GstFlowReturn new_sample_callback(GstElement *sink, gpointer user_data) {
    std::cout << "ğŸ”µ Callback called!" << std::endl;  // ë§¨ ì²«ì¤„ì— ì¶”ê°€
    
    // 1. appsinkì—ì„œ sample ê°€ì ¸ì˜¤ê¸°
    GstSample *sample = gst_app_sink_pull_sample(GST_APP_SINK(sink));
    if (!sample) {
        return GST_FLOW_ERROR;
    }
    
    GstBuffer *buffer = gst_sample_get_buffer(sample);
    GstMapInfo map;
    gst_buffer_map(buffer, &map, GST_MAP_READ);
    
    // 2. ì—¬ê¸°ì— í›„ì²˜ë¦¬ ì½”ë“œ ì‘00000000000000000000000000000000000ì„±00000000000000000000000000000000000000000
    // map.data: NPU ì¶œë ¥ ë°ì´í„° (raw bytes)
    // map.size: ë°ì´í„° í¬ê¸°
00000000000000000000000000000000000000000000000000000000000000000
    auto buffer_data = map.data;
    auto buffer_size = map.size;
    
    in0000000t width = 256;
    int height = 256;000000000000000000000000000 00000000

    if (width*height == map.size){
        std::cout << "datasize is int8"<<std::endl;
    }
    else{
        std::cout << "datasize is fp32"<<std::endl;
    }
    
    // 1. float32ë¡œ ì½ê¸° (NPU ì¶œë ¥)
    cv::Mat depth_map(height, width, CV_32F, (float*)map.data);

    // 2. 0-255ë¡œ ì •ê·œí™”
    cv::Mat depth_normalized;
    cv::normalize(depth_map, depth_normalized, 0, 255, cv::NORM_MINMAX);

    // 3. uint8ë¡œ ë³€í™˜
    cv::Mat depth_uint8;
    depth_normalized.convertTo(depth_uint8, CV_8U);

    // 4. ì»¬ëŸ¬ë§µ ì ìš© (GRAY â†’ BGR uint8)
    cv::Mat depth_colormap;
    cv::applyColorMap(depth_uint8, depth_colormap, cv::COLORMAP_MAGMA);

    // 5. 640x480 ë¦¬ì‚¬ì´ì¦ˆ
    cv::Mat depth_resized;
    cv::resize(depth_colormap, depth_resized, cv::Size(640, 480), 0, 0, cv::INTER_LINEAR);
    
    std::cout << "Resized: " << depth_resized.cols << "x" << depth_resized.rows 
              << " channels=" << depth_resized.channels() << std::endl;
    
    
    // 6. appsrcë¡œ ì „ì†¡
    FrameData *frame_data = new FrameData();
    frame_data->frame = depth_resized.clone(); 
    g_idle_add(show_frame_idle, frame_data); 

    gst_buffer_unmap(buffer, &map);
    gst_sample_unref(sample);
    
    return GST_FLOW_OK;  // âœ… ì—¬ê¸°ì„œ ë!

}

static gboolean opencv_event_handler(gpointer user_data) {
    cv::waitKey(1);  // Qt ì´ë²¤íŠ¸ ì²˜ë¦¬
    return TRUE;  // ê³„ì† ë°˜ë³µ
}



int main(int argc, char *argv[]) {
    // GStreamer ì´ˆê¸°í™”
    gst_init(&argc, &argv);
    
    if (!gst_is_initialized()) {
        std::cerr << "GStreamer ì´ˆê¸°í™” ì‹¤íŒ¨" << std::endl;
        return -1;
    }
    
    std::cout << "GStreamer ì´ˆê¸°í™” ì„±ê³µ" << std::endl;
    
    // ì„¤ì • (í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •)
    std::string device = "/dev/video0";
    std::string hef_path = "./hefs/Midas_v2_small_model.hef"; // HEF íŒŒì¼ ê²½ë¡œ

    // Part 1: ì…ë ¥ â†’ NPU â†’ appsink
    GstElement *pipeline = gst_pipeline_new("hailo-pipeline");
    if (!pipeline) {
        std::cerr << "íŒŒì´í”„ë¼ì¸ ìƒì„± ì‹¤íŒ¨" << std::endl;
        return -1;
    }

    GstElement *source = gst_element_factory_make("v4l2src", "source");
    GstElement *videoconvert1 = gst_element_factory_make("videoconvert", "convert1");  // ì¶”ê°€!
    GstElement *scaler = gst_element_factory_make("videoscale", "scaler");
    GstElement *queue1 = gst_element_factory_make("queue", "queue1");
    GstElement *hailonet = gst_element_factory_make("hailonet", "hailonet");
    GstElement *appsink = gst_element_factory_make("appsink", "app_sink");



    // ì—˜ë¦¬ë¨¼íŠ¸ ìƒì„± í›„ NULL ì²´í¬
    if (!source || !videoconvert1 || !scaler || !queue1 || !hailonet || !appsink) {
        std::cerr << "ì—˜ë¦¬ë¨¼íŠ¸ ìƒì„± ì‹¤íŒ¨!" << std::endl;
        if (!source) std::cerr << "  - source ì‹¤íŒ¨" << std::endl;
        if (!videoconvert1) std::cerr << "  - videoconvert1 ì‹¤íŒ¨" << std::endl;
        if (!scaler) std::cerr << "  - scaler ì‹¤íŒ¨" << std::endl;
        if (!queue1) std::cerr << "  - queue1 ì‹¤íŒ¨" << std::endl;
        if (!hailonet) std::cerr << "  - hailonet ì‹¤íŒ¨" << std::endl;
        if (!appsink) std::cerr << "  - appsink ì‹¤íŒ¨" << std::endl;
        gst_object_unref(pipeline); 
        return -1;
    }


    
    gst_bin_add_many(GST_BIN(pipeline), 
        source, videoconvert1, scaler, queue1, hailonet, appsink, NULL); 

    // Property ì„¤ì •
    g_object_set(source, "device", device.c_str(), NULL);
    g_object_set(hailonet, 
                 "hef-path", hef_path.c_str(),
                 "is-active", TRUE,
                 NULL);

    // appsink ì„¤ì • (ì¤‘ìš”!)
    g_object_set(appsink, 
        "emit-signals", TRUE,
        "sync", FALSE,
        "max-buffers", 1,
        "drop", TRUE,
        NULL);
    g_signal_connect(appsink, "new-sample", G_CALLBACK(new_sample_callback), NULL);



    // Part 1 ì—°ê²°: source â†’ ... â†’ appsink
    GstCaps *caps1 = gst_caps_from_string("video/x-raw,format=RGB,width=256,height=256");


    if (!gst_element_link(source, videoconvert1)) {
        std::cerr << "source â†’ videoconvert1 ë§í¬ ì‹¤íŒ¨" << std::endl;
        return -1;
    }
    if (!gst_element_link(videoconvert1, scaler)) {
        std::cerr << "videoconvert1 â†’ scaler ë§í¬ ì‹¤íŒ¨" << std::endl;
        return -1;
    }
    if (!gst_element_link_filtered(scaler, queue1, caps1)) {
        std::cerr << "scaler â†’ queue1 ë§í¬ ì‹¤íŒ¨" << std::endl;
        return -1;
    }
    if (!gst_element_link(queue1, hailonet)) {
        std::cerr << "queue1 â†’ hailonet ë§í¬ ì‹¤íŒ¨" << std::endl;
        return -1;
    }
    if (!gst_element_link(hailonet, appsink)) {
        std::cerr << "hailonet â†’ appsink ë§í¬ ì‹¤íŒ¨" << std::endl;
        return -1;
    }
    gst_caps_unref(caps1);



    // ë²„ìŠ¤ ì„¤ì •
    GstBus *bus = gst_pipeline_get_bus(GST_PIPELINE(pipeline));
    GMainLoop *loop = g_main_loop_new(NULL, FALSE);
    gst_bus_add_signal_watch(bus);
    


    // íŒŒì´í”„ë¼ì¸ ì‹œì‘
    std::cout << "íŒŒì´í”„ë¼ì¸ ì‹œì‘..." << std::endl;
    GstStateChangeReturn ret = gst_element_set_state(pipeline, GST_STATE_PLAYING);
    
    if (ret == GST_STATE_CHANGE_FAILURE) {
        std::cerr << "íŒŒì´í”„ë¼ì¸ ì‹œì‘ ì‹¤íŒ¨" << std::endl;
        gst_object_unref(pipeline);
        return -1;
    }
    
    // ë©”ì¸ë£¨í”„ ì‹¤í–‰
    g_timeout_add(30, opencv_event_handler, NULL);
    g_main_loop_run(loop);
    
    // ì •ë¦¬
    std::cout << "ì¢…ë£Œ ì¤‘..." << std::endl;
    gst_element_set_state(pipeline, GST_STATE_NULL);
    gst_object_unref(bus);
    gst_object_unref(pipeline);
    g_main_loop_unref(loop);
    
    return 0;
}